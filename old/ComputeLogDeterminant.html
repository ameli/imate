


<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Compute Log-Determinant (imate.ComputeLogDeterminant) &#8212; imate Manual</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom-pydata.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/toggleprompt.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom-pydata.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/logo-imate.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <script defer data-domain="docs.scipy.org" src="https://views.scientific-python.org/js/script.js"></script>

    <!-- Adobe Embed API -->
    <script src="https://documentcloud.adobe.com/view-sdk/viewer.js"></script>

    <!-- My custom JS -->
    <script type="text/javascript" src="../_static/js/custom-pydata.js"></script>

    <!-- Syntax highlighting for BibTex code blocks -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-solarizedlight.min.css"/>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js"></script>

    
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../contents.html">
  
  
  
  
    <img src="../_static/images/icons/logo-imate-light.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/images/icons/logo-imate-dark.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/install.html">
  1. Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/docker.html">
  2. Docker
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/gpu.html">
  3. GPU
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ameli/imate" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://pypi.org/project/imate/" rel="noopener" target="_blank" title="PyPI"><span><i class="fab fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://anaconda.org/s-ameli/imate" rel="noopener" target="_blank" title="Anaconda Cloud"><span><i class="fa fa-circle-notch"></i></span>
            <label class="sr-only">Anaconda Cloud</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://hub.docker.com/r/sameli/imate" rel="noopener" target="_blank" title="Docker Hub"><span><i class="fab fa-docker"></i></span>
            <label class="sr-only">Docker Hub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mybinder.org/v2/gh/ameli/imate/HEAD?filepath=notebooks%2FInterpolateTraceOfInverse.ipynb" rel="noopener" target="_blank" title="Lanuch Jupyter on Binder"><span><i class="fa fa-chart-line"></i></span>
            <label class="sr-only">Lanuch Jupyter on Binder</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
    
    
  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#usage">
   Usage
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters">
   Parameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mathematical-details">
   Mathematical Details
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cholesky-decomposition-method">
     Cholesky Decomposition Method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-lanczos-quadrature-method">
     Stochastic Lanczos Quadrature Method
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#examples">
   Examples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dense-matrix">
     Dense Matrix
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-matrix">
     Sparse Matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#api">
   API
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#main-interface">
     Main Interface
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modules">
     Modules
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      

<div class="tocsection editthispage">
    <a href="https://github.com/https://github.com/ameli/imate/edit/main/docs/source/old/ComputeLogDeterminant.rst">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="compute-log-determinant-imate-computelogdeterminant">
<span id="computelogdeterminant-userguide"></span><h1>Compute Log-Determinant (<code class="xref py py-mod docutils literal notranslate"><span class="pre">imate.ComputeLogDeterminant</span></code>)<a class="headerlink" href="#compute-log-determinant-imate-computelogdeterminant" title="Permalink to this heading">#</a></h1>
<p>The sub-package <code class="xref py py-mod docutils literal notranslate"><span class="pre">imate.ComputeLogDeterminant</span></code> computes the log-determinant of an invertible matrix.</p>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">GenerateMatrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">ComputeLogDeterminant</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate a symmetric positive-definite matrix of the shape (20**2,20**2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">GenerateMatrix</span><span class="p">(</span><span class="n">NumPoints</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute trace of inverse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logdet</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<p>In the above, the class <code class="xref py py-class docutils literal notranslate"><span class="pre">GenerateMatrix</span></code> produces a sample matrix for test purposes (see <span class="xref std std-ref">Generate Matrix</span> for details).</p>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">ComputeLogDeterminant</span></code> module in the above code employs the <em>Cholesky method</em> by default to compute the log-determinant. However, other methods can be employed by setting <a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a> argument according to the table below.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a></p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Matrix size</p></th>
<th class="head"><p>Matrix type</p></th>
<th class="head"><p>Results</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">'cholesky'</span></code></p></td>
<td><p><a class="reference internal" href="#mathdetails-cholesky"><span class="std std-ref">Cholesky decomposition</span></a></p></td>
<td><p>small</p></td>
<td><p>dense, sparse</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code></p></td>
<td><p><a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos Quadrature</span></a></p></td>
<td><p>small, large</p></td>
<td><p>dense, sparse</p></td>
<td><p>approximation</p></td>
</tr>
</tbody>
</table>
<p>In the following example, we apply the <em>SLQ randomized estimator</em> method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Using SLQ method with 20 Monte-Carlo iterations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logdet</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;SLQ&#39;</span><span class="p">,</span><span class="n">NumIterations</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<p>Each of the methods in the above accepts some options. For instance, the SLQ method accepts <a class="reference internal" href="ComputeTraceOfInverse.html#NumIterations" title="NumIterations"><code class="xref py py-attr docutils literal notranslate"><span class="pre">NumIterations</span></code></a> argument, which sets the number of Monte-Carlo trials. To see the detailed list of all arguments for each method, see <a class="reference internal" href="#parameters-logdet"><span class="std std-ref">Parameters</span></a> and the <a class="reference external" href="https://ameli.github.io/imate/_modules/modules.html">API</a> of the package.</p>
</section>
<section id="parameters">
<span id="parameters-logdet"></span><h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading">#</a></h2>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">imate.ComputeLogDeterminant</span></code> module accepts the following attributes as input argument.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="A">
<span class="sig-name descname"><span class="pre">A</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">numpy.ndarray,</span> <span class="pre">or</span> <span class="pre">scipy.sparse.csc_matrix</span></em><a class="headerlink" href="#A" title="Permalink to this definition">#</a></dt>
<dd><p>An invertible sparse or dense matrix.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="ComputeMethod">
<span class="sig-name descname"><span class="pre">ComputeMethod</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">string</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'cholesky'</span></em><a class="headerlink" href="#ComputeMethod" title="Permalink to this definition">#</a></dt>
<dd><p>Specifies the method of computation. The methods are one of <code class="docutils literal notranslate"><span class="pre">'cholsky'</span></code> and <code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code> (see <a class="reference internal" href="#mathdetails-logdet"><span class="std std-ref">Mathematical Details</span></a>).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="NumIterations">
<span class="sig-name descname"><span class="pre">NumIterations</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#NumIterations" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter is only applied to <code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code> computing methods (see <a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a>).</p>
<p>The number of iterations refers to the number of Monte-Carlo samplings during the randomized estimators. With the larger number of Monte-Carlo samples, better numerical convergence is obtained.</p>
<p>For mathematical details of this parameter, see <a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos quadrature method</span></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="LanczosDegree">
<span class="sig-name descname"><span class="pre">LanczosDegree</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">20</span></em><a class="headerlink" href="#LanczosDegree" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter is only applied to <code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code> computing method (see <a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a>).</p>
<p>The Lanczos degree is the number of Lanczos iterations during the Lanczos tridiagonalization process in stochastic Lanczos quadrature (SLQ) method. Larger Lanczos degree yields better numerical convergence.</p>
<p>For mathematical detail of this parameter, see <a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos quadrature method</span></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="UseLanczosTridiagonalization">
<span class="sig-name descname"><span class="pre">UseLanczosTridiagonalization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#UseLanczosTridiagonalization" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter is only applied to <code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code> computing method (see <a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a>).</p>
<ul class="simple">
<li><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <em>Lanczos tri-diagonalization</em> method is used.</p></li>
<li><p>When set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <em>Golub-Kahn-Lanczos bi-diagonalization</em> method is used.</p></li>
</ul>
<p>For mathematical details of this parameter, see <a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos quadrature method</span></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="Verbose">
<span class="sig-name descname"><span class="pre">Verbose</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#Verbose" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, prints some information about the process.</p>
</dd></dl>

</section>
<section id="mathematical-details">
<span id="mathdetails-logdet"></span><h2>Mathematical Details<a class="headerlink" href="#mathematical-details" title="Permalink to this heading">#</a></h2>
<p>The three methods of computing the log-determinant is described below. These methods are categorized into two groups:</p>
<ol class="arabic simple">
<li><p><strong>Exact:</strong> The <a class="reference internal" href="#mathdetails-cholesky"><span class="std std-ref">Cholesky decomposition method</span></a> aims to compute the log-determinant of a matrix exactly. The exact method is expensive and suitable for only small matrices.</p></li>
<li><p><strong>Aproximation:</strong> The <a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">stochastic Lanczos quadrature method</span></a> are <em>randomized estimation algorithms</em> that estimate the log-determinant with <em>Monte-Carlo sampling</em>. These methods do not compute the determinant exactly, but over the iterations, their approximation converges to the true solution. These methods are very suitable for large matrices.</p></li>
</ol>
<p>The table below describes which method is suitable for <strong>symmetric</strong> (sym) and/or <strong>positive-definite</strong> (PD) matrices.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><a class="reference internal" href="ComputeTraceOfInverse.html#ComputeMethod" title="ComputeMethod"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ComputeMethod</span></code></a></p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Sym</p></th>
<th class="head"><p>PD</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">'cholesky'</span></code></p></td>
<td><p><a class="reference internal" href="#mathdetails-cholesky"><span class="std std-ref">Cholesky decomposition</span></a></p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">'SLQ'</span></code></p></td>
<td><p><a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos Quadrature</span></a> (using Lanczos Algorithm)</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p><a class="reference internal" href="#mathdetails-slq"><span class="std std-ref">Stochastic Lanczos Quadrature</span></a> (using Golub-Kahn Algorithm)</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
<p>Also, in the above table, we recall that the <em>Lanczos</em> and <em>Golub-khan</em> algorithms can be selected by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">UseLanczosTridiagonalizaton</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>, respectively.</p>
<section id="cholesky-decomposition-method">
<span id="mathdetails-cholesky"></span><h3>Cholesky Decomposition Method<a class="headerlink" href="#cholesky-decomposition-method" title="Permalink to this heading">#</a></h3>
<p>The log-determinant of an invertible matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> can be computed via</p>
<div class="math notranslate nohighlight">
\[\log | \mathbf{A} | = 2 \mathrm{trace}( \log \mathrm{diag}(\mathbf{L})).\]</div>
<p>In this package, the Cholesky decomposition computed via <a class="reference external" href="https://people.engr.tamu.edu/davis/suitesparse.html">Suite Sparse</a> package <a class="reference internal" href="ComputeTraceOfInverse.html#davis-2006" id="id1"><span>[Davis-2006]</span></a> (see <span class="xref std std-ref">installation</span>). If this package is not installed, the Cholesky decomposition is computed using <code class="docutils literal notranslate"><span class="pre">scipy</span></code> package instead.</p>
</section>
<section id="stochastic-lanczos-quadrature-method">
<span id="mathdetails-slq"></span><h3>Stochastic Lanczos Quadrature Method<a class="headerlink" href="#stochastic-lanczos-quadrature-method" title="Permalink to this heading">#</a></h3>
<p>The stochastic Lanczos quadrature (SLQ) method combines stochastic estimator and the Gauss quadrature technique. A stochastic estimator approximates the log-determinant by</p>
<div class="math notranslate nohighlight">
\[\log | \mathbf{A} | = \mathrm{trace}(\log \mathbf{A}) = \mathbb{E} \left[ \boldsymbol{q}^{\intercal} (\log \mathbf{A}) \boldsymbol{q} \right]
\approx \frac{n}{m} \sum_{i=1}^m \boldsymbol{q}_i^{\intercal} (\log \mathbf{A}) \boldsymbol{q}_i\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{q}_i\)</span> are unit random vectors obtained from random Rademacher distribution that are normalized to unit norm.</p>
<p>In the SLQ method, first, an <span class="math notranslate nohighlight">\((l \times l)\)</span> tri-diagonal matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> is formed by the Lanczos tri-diagonalization of the matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> (see p. 57 of <a class="reference internal" href="ComputeTraceOfInverse.html#bai-2000" id="id2"><span>[Bai-2000]</span></a>). The <em>Lanczos degree</em> <span class="math notranslate nohighlight">\(l\)</span> can be set by the parameter <a class="reference internal" href="ComputeTraceOfInverse.html#LanczosDegree" title="LanczosDegree"><code class="xref py py-attr docutils literal notranslate"><span class="pre">LanczosDegree</span></code></a>.</p>
<p>The term on the right side in the above is approximated by the Gaussian quadrature (see <a class="reference internal" href="ComputeTraceOfInverse.html#bai-1996" id="id3"><span>[Bai-1996]</span></a> and <a class="reference internal" href="ComputeTraceOfInverse.html#golub-2009" id="id4"><span>[Golub-2009]</span></a>), by</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{q}_i^{\intercal} (log \mathbf{A}) \boldsymbol{q}_i = \sum_{j=0}^l \left( \tau_{j1} \right)^2 \log \theta_j.\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_j\)</span> is the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> eigenvalue of the tri-diagonalized matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>. Also, <span class="math notranslate nohighlight">\(\tau_{j1}\)</span> is the first element of the vector <span class="math notranslate nohighlight">\(\boldsymbol{\tau}_j = (\tau_{j1},\dots,\tau_{jn})\)</span> where <span class="math notranslate nohighlight">\(\boldsymbol{\tau}_j\)</span> is the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> eigenvector of <span class="math notranslate nohighlight">\(\mathbf{T}\)</span> (see Algorithm 1 of <a class="reference internal" href="ComputeTraceOfInverse.html#ubaru-2017" id="id5"><span>[Ubaru-2017]</span></a>).</p>
<p>Alternatively, instead of the tri-diagonalized matrix <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>, one might use the bi-diagonalized matrix <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> that is obtained by Golub-Kahn-Lanczos bi-diagonalization (see p. 143 of <a class="reference internal" href="ComputeTraceOfInverse.html#bai-2000" id="id6"><span>[Bai-2000]</span></a>, p. 495 of <a class="reference internal" href="ComputeTraceOfInverse.html#golub-1996" id="id7"><span>[Golub-1996]</span></a>). This way, the above them is computed by</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{q}_i^{\intercal} \mathbf{A}^{-1} \boldsymbol{q}_i = \sum_{j=0}^l \left( \tau_{j1} \right)^2 \log \phi_j.\]</div>
<p>where here <span class="math notranslate nohighlight">\(\phi_j\)</span> is the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> singular value of <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>. Also, <span class="math notranslate nohighlight">\(\tau_{j1}\)</span> denotes the first entry of the <span class="math notranslate nohighlight">\(j\)</span><sup>th</sup> right singular vector of <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> (see Algorithm 2 of <a class="reference internal" href="ComputeTraceOfInverse.html#ubaru-2017" id="id8"><span>[Ubaru-2017]</span></a>).</p>
<p>In this module, by setting <a class="reference internal" href="ComputeTraceOfInverse.html#UseLanczosTridiagonalization" title="UseLanczosTridiagonalization"><code class="xref py py-attr docutils literal notranslate"><span class="pre">UseLanczosTridiagonalization</span></code></a> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the Lanczos tri-diagonalization method is applied. Whereas if this parameter is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the Golub-Kahn-Lanczos bi-diagonalization is used.</p>
<dl class="simple">
<dt>Comparison of Lanczos and Golub-Kahn methods:</dt><dd><ul class="simple">
<li><p>The Lanczos tri-diagonalization method can only be applied to <strong>symmetric</strong> matrices. Whereas the Golub-Kahn bi-diagonalization method can be used for <strong>non-symmetric</strong> matrices.</p></li>
<li><p>The Lanczos tri-diagonalization method is almost <strong>twice faster</strong> than the Golub-Kahn bi-diagonalization method on symmetric matrices. This is because the former has one matrix-vector multiplication per iterations, whereas the latter has two.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When the matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is very close to the identity matrix, the Golub-Kahn bi-diagonalization method that is implemented in this module is unstable.</p>
</div>
</section>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">#</a></h2>
<section id="dense-matrix">
<h3>Dense Matrix<a class="headerlink" href="#dense-matrix" title="Permalink to this heading">#</a></h3>
<p>In the code below, we compare the three computing methods for a small dense matrix of the shape <span class="math notranslate nohighlight">\((20^2,20^2)\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import modules</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">GenerateMatrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">ComputeLogDeterminant</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate a matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">GenerateMatrix</span><span class="p">(</span><span class="n">NumPoints</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Try various methods</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D1</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;cholesky&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D2</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;SLQ&#39;</span><span class="p">,</span><span class="n">NumIterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">LanczosDegree</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">UseLanczosTridiagonalization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D3</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;SLQ&#39;</span><span class="p">,</span><span class="n">NumIterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">LanczosDegree</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">UseLanczosTridiagonalization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The results are shown in the table below. The last column is the elapsed time in seconds. The fifth column is the relative error compared to the Cholesky method. Recall that the Cholesky method computes the log-determinant exactly, hence, it can be used as the benchmark solution. The randomized methods do not much advantage over the exact method for small matrices as their elapsed time higher.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Method</p></th>
<th class="head"><p>Options</p></th>
<th class="head"><p>Result</p></th>
<th class="head"><p>Error</p></th>
<th class="head"><p>Time</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">D1</span></code></p></td>
<td><p>Cholesky</p></td>
<td><p>N/A</p></td>
<td><p>41.675</p></td>
<td><p>0.00%</p></td>
<td><p>0.00</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">D2</span></code></p></td>
<td><p>SLQ</p></td>
<td><p><span class="math notranslate nohighlight">\(m = 50\)</span>, <span class="math notranslate nohighlight">\(l = 30\)</span>, tri-diagonalization</p></td>
<td><p>38.104</p></td>
<td><p>8.57%</p></td>
<td><p>0.24</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">D3</span></code></p></td>
<td><p>SLQ</p></td>
<td><p><span class="math notranslate nohighlight">\(m = 50\)</span>, <span class="math notranslate nohighlight">\(l = 30\)</span>, bi-diagonalization</p></td>
<td><p>41.466</p></td>
<td><p>0.50%</p></td>
<td><p>0.35</p></td>
</tr>
</tbody>
</table>
<p>The above table can be produced by running the test script <a class="reference external" href="https://github.com/ameli/imate/blob/main/tests/test_ComputeLogDeterminant.py"><code class="docutils literal notranslate"><span class="pre">/test/test_ComputeLogDeterminant.py</span></code></a>, although, the results might be slightly difference due to the random number generator.</p>
</section>
<section id="sparse-matrix">
<h3>Sparse Matrix<a class="headerlink" href="#sparse-matrix" title="Permalink to this heading">#</a></h3>
<p>In the code below, we compare the three computing methods for a large sparse matrix of the shape <span class="math notranslate nohighlight">\((50^2,50^2)\)</span> and sparse density <span class="math notranslate nohighlight">\(d = 0.01\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import modules</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">GenerateMatrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">imate</span> <span class="kn">import</span> <span class="n">ComputeLogDeterminant</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate a matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">GenerateMatrix</span><span class="p">(</span><span class="n">NumPoints</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">KernelThreshold</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">DecorrelationScale</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span><span class="n">UseSparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">RunInParallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Try various methods</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D1</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;cholesky&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D2</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;SLQ&#39;</span><span class="p">,</span><span class="n">NumIterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">LanczosDegree</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">UseLanczosTridiagonalization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D3</span> <span class="o">=</span> <span class="n">ComputeLogDeterminant</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">ComputeMethod</span><span class="o">=</span><span class="s1">&#39;SLQ&#39;</span><span class="p">,</span><span class="n">NumIterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">LanczosDegree</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">UseLanczosTridiagonalization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The results are shown in the table below.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Method</p></th>
<th class="head"><p>Options</p></th>
<th class="head"><p>Result</p></th>
<th class="head"><p>Error</p></th>
<th class="head"><p>Time</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">D1</span></code></p></td>
<td><p>Cholesky</p></td>
<td><p>N/A</p></td>
<td><p>52.052</p></td>
<td><p>0.00%</p></td>
<td><p>2.44</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">D2</span></code></p></td>
<td><p>SLQ</p></td>
<td><p><span class="math notranslate nohighlight">\(m = 50\)</span>, <span class="math notranslate nohighlight">\(l = 30\)</span>, tri-diagonalization</p></td>
<td><p>51.955</p></td>
<td><p>0.19%</p></td>
<td><p>0.76</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">D3</span></code></p></td>
<td><p>SLQ</p></td>
<td><p><span class="math notranslate nohighlight">\(m = 50\)</span>, <span class="math notranslate nohighlight">\(l = 30\)</span>, bi-diagonalization</p></td>
<td><p>51.711</p></td>
<td><p>0.66%</p></td>
<td><p>1.35</p></td>
</tr>
</tbody>
</table>
<p>The advantages of randomized methods can be clearly observed on large sparse matrices. In the above table, the Cholesky method took two minutes, whereas the randomized approaches took one or two seconds to compute. Moreover, a considerable accuracy is achieved with only a few Monte-Carlo sampling (<span class="math notranslate nohighlight">\(m = 50\)</span>). The SLQ method with bi-diagonalization produced less accurate result compared to the tri-diagonalization method. However, by increasing the Lanczos degree, the accuracy of bi-diagonalization method improves.</p>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="davis-2006" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">Davis-2006</a><span class="fn-bracket">]</span></span>
<p>Davis, T. A. (2006). Direct Methods for Sparse Linear Systems. Society for Industrial and Applied Mathematics, <a class="reference external" href="https://doi.org/10.1137/1.9780898718881">doi: 10.1137/1.9780898718881</a></p>
</div>
<div class="citation" id="bai-1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">Bai-1996</a><span class="fn-bracket">]</span></span>
<p>Bai, Z., Fahey, G., and Golub, G. (1996). Some large-scale matrix computation problems. <em>Journal of Computational and Applied Mathematics</em>, 74(1), 71 â€“ 89. <a class="reference external" href="https://doi.org/10.1016/0377-0427(96)00018-0">doi : 10.1016/0377-0427(96)00018-0</a></p>
</div>
<div class="citation" id="bai-2000" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Bai-2000<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>Bai, Z, Demmel, J., Dongarra, J., Ruhe, A., van der Vorst, H. (2000). Templates for the Solution of Algebraic Eigenvalue Problem, A Practical Guide. Society for Industrial and Applied Mathematics. <a class="reference external" href="https://doi.org/10.1137/1.9780898719581">doi:10.1137/1.9780898719581</a></p>
</div>
<div class="citation" id="golub-1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">Golub-1996</a><span class="fn-bracket">]</span></span>
<p>Golub, G. H. &amp; Van Loan, C. F. (1996). Matrix Computations. Johns Hopkins Studies in the Mathematical Sciences. Johns Hopkins University Press. <a class="reference external" href="https://jhupbooks.press.jhu.edu/title/matrix-computations">ISBN: 9781421407944</a></p>
</div>
<div class="citation" id="golub-2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">Golub-2009</a><span class="fn-bracket">]</span></span>
<p>Golub, G. H. &amp; Meurant, G. (2009). Matrices, Moments and Quadrature with Applications. USA: Princeton University Press. <a class="reference external" href="https://doi.org/10.1007/s10208-010-9082-0">doi: 10.1007/s10208-010-9082-0</a></p>
</div>
<div class="citation" id="ubaru-2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Ubaru-2017<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id5">1</a>,<a role="doc-backlink" href="#id8">2</a>)</span>
<p>Ubaru, S., Chen, J., &amp; Saad, Y. (2017). Fast estimation of <span class="math notranslate nohighlight">\(\mathrm{tr}(f(A))\)</span> via stochastic Lanczos quadrature. <em>SIAM Journal on Matrix Analysis and Applications</em>, 38(4), 1075-1099. <a class="reference external" href="https://doi.org/10.1137/16M1104974">doi: 10.1137/16M1104974</a></p>
</div>
</div>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="Permalink to this heading">#</a></h2>
<section id="main-interface">
<h3>Main Interface<a class="headerlink" href="#main-interface" title="Permalink to this heading">#</a></h3>
</section>
<section id="modules">
<h3>Modules<a class="headerlink" href="#modules" title="Permalink to this heading">#</a></h3>
</section>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, Siavash Ameli.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>