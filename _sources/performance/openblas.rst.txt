.. _perf-openblas:

Comparison of Performance with and without OpenBLAS
***************************************************

Almost all computational software are built upon existing numerical libraries for basic linear algebraic subprograms (BLAS), such as `BLAS <https://netlib.org/blas/>`__, `OpenBLAS <https://www.openblas.net>`__, `NVIDIA速 cuBLAS <https://developer.nvidia.com/cublas>`__, `NVIDIA速 cuSparse <https://docs.nvidia.com/cuda/cusparse/index.html>`__, and `Intel速 Math Kernel Library <https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html#gs.bafzhk>`__, to name a few. |project| uses cuBLAS and cuSparse for basic vector and matrix operations on GPU devices. However, for computation on CPU, |project| comes with `its own library <../doxygen/html/annotated.html>`__ for basic numerical operations for vector and matrix operations, which supports both dense and sparse matrices. Despite this, |project| can also be compiled with `OpenBLAS <https://www.openblas.net/>`__ instead of its own library.

.. note::

    OpenBLAS library has three levels of functionalities: levels one, two, and three, respectively for vector-vector, matrix-vector, and matrix-matrix operations. OpenBLAS, however, only supports operations on dense matrices. As such, when |project| is compiled with OpenBLAS, it only uses level one functionalities of OpenBLAS for sparse data. For level two and three operations, |project| uses its own library.

The following numerical experiment compares the performance and accuracy of |project| with and without using OpenBLAS.

Test Description
================

In the following numerical experiments, the goal is to compute

.. math::
    :label: traceinv2
    
    \mathrm{trace}(\mathbf{A}^{-1}),

where :math:`\mathbf{A}` is symmetric and positive-definite. The above quantity is a computationally expensive expression that frequently appears in the Jacobian and Hessian of likelihood functions in machine learning.

Algorithm
---------

To compute :math:numref:`traceinv`, the stochastic Lanczos quadrature (SLQ) algorithm is employed. The complexity of this algorithm is

.. math::
   :label: complexity2

    \mathcal{O} \left( (\mathrm{nnz}(\mathbf{A}) l + n l^2) s \right),

where :math:`n` is the matrix size, :math:`\mathrm{nnz}(\mathbf{A})` is the number of nonzero elements of the sparse matrix :math:`\mathbf{A}`, :math:`l` is the number of Lanczos iterations, and :math:`s` is the number of Monte-Carlo iterations (see details in :ref:`imate.traceinv.slq`).  The numerical experiment is performed with :math:`l=80` and :math:`s=200`. The computations were carried out on Intel速 Xeon CPU E5-2670 v3  with 24 threads.

Arithmetic Types
----------------

The benchmark test also examines the performance and accuracy of |project| on various arithmetic types of the matrix data. To this end, the matrices that are described below are re-cast into 32-bit, 64-bit, and 128-bit floating point types.

.. note::

    Supporting 128-bit data types is one of the features of |project|, which is often not available in numerical libraries, such as OpenBLAS.

Test on Dense Matrices
======================

The Gramian matrix :math:`\mathbf{A} = \mathbf{B}^{\intercal} \mathbf{B}` is considered for the test where :math:`\mathbf{B}` is a bi-diagonal Toeplitz matrix defined by

.. math::

    B_{ij} =
    \begin{cases}
        a, & i = j, \\
        b, & i+1 = j.
    \end{cases}

The above matrix can be generated by :func:`imate.toeplitz` function. In this experiment, :math:`a = 2`, :math:`b = 1`, and the matrix size is varied by powers of two, :math:`n = 2^8, 2^9, \dots, 2^{14}`.

An advantage of using the above matrix is that an analytic formula for :math:numref:`traceinv2` for :math:`n \gg 1` is known by

.. math::
   :label: analytic-formula

    \mathrm{trace}(\mathbf{A}^{-1}) \approx \frac{1}{a^2 - b^2} \left( n - \frac{q^{2}}{1 - q^2} \right),

where :math:`q = b/a`. See :func:`imate.sample_matrices.toeplitz_traceinv` for details. The above analytic formula is used as the benchmark solution to test the accuracy of the results.

Process Time
------------

The processing time of the computations is shown in the figure below. The speed of computation with and without using OpenBLAS for :math:`n < 10^{12}` shows mixed results. However, at :math:`n \geq 2^{12}`, the speed of computation without using OpenBLAS is consistently superior by a factor of roughly 1.5 to 2.5.

.. image:: ../_static/images/performance/benchmark_openblas_dense_time.png
   :align: center
   :class: custom-dark

Floating Point Arithmetic Accuracy
----------------------------------

The accuracy of floating point arithmetic is compared with and without using OpenBLAS in the next figure. The error is obtained by comparing the results with :math:numref:`analytic-formula` as the benchmark. The figure implies that the results of both 32-bit and 64-bit data types with and without openBLAS are almost insignificant.

.. image:: ../_static/images/performance/benchmark_openblas_dense_accuracy.png
   :align: center
   :class: custom-dark

Recall that the SLQ method is a randomized algorithm, hence, the results are not deterministic. To diminish the effect of the randomness of the algorithm, the numerical experiment is repeated ten times. The standard deviation of the results is shown by the error bars in the figure. However, the values of the plot itself are not the average of the results, rather, only the result of one of the repeats is shown in order to demonstrate the error after 200 Monte-Carlo iterations (and not 10 times 200 iterations).

Test on Sparse Matrices
=======================

As noted above, OpenBLAS only supports dense matrices. However, |project| can yet utilize level one functions of OpenBLAS for sparse matrices. The following examines the performance on sparse matrices.

The table below shows the sparse matrices used in the test, which are chosen from `SuiteSparse Matrix Collection <https://sparse.tamu.edu>`__ and are obtained from real applications. The matrices in the table below are all symmetric positive-definite. The number of nonzero elements (nnz) of these matrices increases approximately by a factor of 5 on average and their sparse density remains at the same order of magnitude (except for the first three).

.. table::
   :class: right2 right3

   =================  =========  ===========  =======  ============================
   Matrix Name             Size  nnz          Density  Application
   =================  =========  ===========  =======  ============================
   |nos5|_                  468        5,172  0.02     Structural Problem
   |mhd4800b|_            4,800       27,520  0.001    Electromagnetics
   |bodyy6|_             19,366      134,208  0.0003   Structural Problem
   |G2_circuit|_        150,102      726,674  0.00003  Circuit Simulation
   |parabolic_fem|_     525,825    3,674,625  0.00001  Computational Fluid Dynamics
   |StocF-1465|_      1,465,137   21,005,389  0.00001  Computational Fluid Dynamics 
   |Bump_2911|_       2,911,419  127,729,899  0.00001  Structural Problem
   |Queen_4147|_      4,147,110  329,499,284  0.00002  Structural Problem
   =================  =========  ===========  =======  ============================

.. |nos5| replace:: ``nos5``
.. _nos5: https://sparse.tamu.edu/HB/nos5
.. |mhd4800b| replace:: ``mhd4800b``
.. _mhd4800b: https://sparse.tamu.edu/Bai/mhd4800b
.. |bodyy6| replace:: ``bodyy6``
.. _bodyy6: https://sparse.tamu.edu/Pothen/bodyy6
.. |G2_circuit| replace:: ``G2_circuit``
.. _G2_circuit: https://sparse.tamu.edu/AMD/G2_circuit
.. |parabolic_fem| replace:: ``parabolic_fem``
.. _parabolic_fem: https://sparse.tamu.edu/Wissgott/parabolic_fem
.. |StocF-1465| replace:: ``StocF-1465``
.. _StocF-1465: https://sparse.tamu.edu/Janna/StocF-1465
.. |Bump_2911| replace:: ``Bump_2911``
.. _Bump_2911: https://sparse.tamu.edu/Janna/Bump_2911
.. |Queen_4147| replace:: ``Queen_4147``
.. _Queen_4147: https://sparse.tamu.edu/Janna/Queen_4147

Floating Point Arithmetic Accuracy
----------------------------------

The accuracy of floating point arithmetic is compared with and without using OpenBLAS in the next figure. The error is obtained by comparing the results with the computation on 128-bit data type without using OpenBLAS as the benchmark. The figure implies that the results of both 32-bit and 64-bit data types with and without openBLAS are almost insignificant at :math:`\mathrm{nnz}(\mathbf{A}) < 10^7` or for 32-bit data types. In contrast, for larger matrices and 64-bit data type, the |project| library without OpenBLAS significantly produces less arithmetic error compared with OpenBLAS.

.. image:: ../_static/images/performance/benchmark_openblas_sparse_accuracy.png
   :align: center
   :height: 375
   :class: custom-dark

Why |project| Has Better Arithmetic Accuracy?
---------------------------------------------

.. sidebar:: Types in Reduction Operation
   :class: custom-sidebar

   .. table::
      :class: custom-table
   
      +--------------+----------+--------------+
      | :math:`a, b` | .. centered:: :math:`c` |
      +              +----------+--------------+
      |              |     BLAS | |project|    |
      +==============+==========+==============+
      | 32-bit       | 32-bit   | 128-bit      |
      +--------------+----------+--------------+
      | 64-bit       | 64-bit   | 128-bit      |
      +--------------+----------+--------------+
      | 128-bit      | N/A      | 128-bit      |
      +--------------+----------+--------------+

The difference in arithmetic error between OpenBLAS and |project| is surprisingly simple and is related to how the *sum-reduction* operation

.. math::
   c \gets \sum_{i=1}^n a_i b_i,

is implemented. In OpenBLAS (and several other BLAS-type libraries), the type of the summation variable :math:`c` is the same as the type of input variables :math:`a_i` and :math:`b_i`. In contrast, in |project|, the type of :math:`c` is always 128-bit (see table below), and once the sum-reduction operation is done, :math:`c` is cast down to the type of :math:`a_i` and :math:`b_i`.

When :math:`a_i` and :math:`b_i` is 32-bit, the effect of the above resolution is negligible compared to large arithmetic errors of 32-bit type. However, for 64-bit data, which has smaller arithmetic errors, the effect of the above resolution is noticeable as shown by the above figure.

Elapsed Time
------------

The figure below shows the elapsed (wall) time of the computation. For small matrices, :math:`\mathrm{nnz}(\mathbf{A}) < 10^{5}`, the results with and without OpenBLAS are comparable. However, for larger matrices, there is a significant difference between the two experiments where OpenBLAS is consistently slower than the built-in |project| library by a factor of at least two.

.. image:: ../_static/images/performance/benchmark_openblas_sparse_time.png
   :align: center
   :class: custom-dark

Scalability with CPU Cores
--------------------------

The scalability of computation is shown in the figure below by the elapsed time versus the number of CPU cores. OpenBLAS is less scalable as the curves in the figure saturate (depart from the linear behavior) more quickly compared to no OpenBLAS.

.. image:: ../_static/images/performance/benchmark_openblas_sparse_cores.png
   :align: center
   :height: 375
   :class: custom-dark

How to Reproduce Results
========================

Prepare Matrix Data
-------------------

1. Download all the above-mentioned sparse matrices from `SuiteSparse Matrix Collection <https://sparse.tamu.edu>`__. For instance, download ``Queen_4147.mat`` from |Queen_4147|_.
2. Run |read_matrix_m|_ to extract sparse matrix data from ``Queen_4147.mat``:

   .. code-block:: matlab

        read_matrix('Queen_4147.mat');

3. Run |read_matrix_py|_ to convert the outputs of the above script to generate a python pickle file:

   .. prompt:: bash

        read_matrix.py Queen_4147 float32    # to generate 32-bit data
        read_matrix.py Queen_4147 float64    # to generate 64-bit data
        read_matrix.py Queen_4147 float128   # to generate 128-bit data

   The output of the above script will be written in |matrices|_.

Perform Numerical Test
----------------------

Run each of the scripts described below with and without using OpenBLAS support in |project| to compare their performance. The default installation of |project| (if you installed it with ``pip`` or ``cond``) does not come with OpenBLAS support. To use OpenBLAS, |project| has to be compiled from the source.

.. tip::

    To compile |project| using OpenBLAS, export the environment variable:

    .. prompt:: bash

        export USE_CBLAS=1

    or set ``USE_CBLAS=1`` in |def-use-cblas|_. By default, ``USE_CBLAS`` is set to ``0``. Then, recompile |project|. See :ref:`Compile from Source <compile-source>`.

.. |def-use-cblas|  replace:: ``/imate/_definitions/definition.h``
.. _def-use-cblas: https://github.com/ameli/imate/blob/main/imate/_definitions/definitions.h#L67

Dense Matrices, Run Locally
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Run |benchmark_openblas_py|_ as follows:

1. To reproduce the results *without OpenBLAS*:

   .. prompt:: bash
  
       cd /imate/benchmark/scripts
       python ./benchmark_openblas_dense.py -o False

2. To reproduce the results *with OpenBLAS*, first, compile |project| with OpenBLAS (see above), then run:

   .. prompt:: bash
  
       cd /imate/benchmark/scripts
       python ./benchmark_openblas_dense.py -o True

Dense Matrices, Submit to Cluster with SLURM
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Submit the job file |jobfile_openblas_sh|_ by

.. prompt:: bash

    cd /imate/benchmark/jobfiles
    sbatch jobfile_benchmark_openblas_dense.sh

To use with or without OpenBLAS, modify the above job files (uncomment lines the corresponding).

Sparse Matrices, Run Locally
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Run |benchmark_speed_py|_ script as follows:

.. prompt:: bash

    cd /imate/benchmark/scripts
    python ./benchmark_speed.py -c

Sparse Matrices, Submit to Cluster with SLURM
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Submit the job file |jobfile_speed_cpu_sh|_ by

.. prompt:: bash

    cd /imate/benchmark/jobfiles
    sbatch jobfile_benchmark_speed_cpu.sh
    
Plot Results
------------

* Run |notebook_openblas_dense_ipynb|_ to generate plots for the dense matrices shown in the above
* Run |notebook_openblas_sparse_ipynb|_ to generate plots for the sparse matrices shown in the above

These notebooks stores the plots as `svg` files in |svg_plots|_.
    
.. |read_matrix_m| replace:: ``/imate/benchmark/matrices/read_matrix.m``
.. _read_matrix_m: https://github.com/ameli/imate/blob/main/benchmark/matrices/read_matrix.m

.. |read_matrix_py| replace:: ``/imate/benchmark/matrices/read_matrix.py``
.. _read_matrix_py: https://github.com/ameli/imate/blob/main/benchmark/matrices/read_matrix.py

.. |matrices| replace:: ``/imate/benchmark/matrices/``
.. _matrices: https://github.com/ameli/imate/blob/main/benchmark/matrices

.. |benchmark_openblas_py| replace:: ``/imate/benchmark/scripts/benchmark_openblas_dense.py``
.. _benchmark_openblas_py: https://github.com/ameli/imate/blob/main/benchmark/scripts/benchmark_openblas_dense.py

.. |benchmark_speed_py| replace:: ``/imate/benchmark/scripts/benchmark_speed.py``
.. _benchmark_speed_py: https://github.com/ameli/imate/blob/main/benchmark/scripts/benchmark_speed.py

.. |jobfile_speed_cpu_sh| replace:: ``/imate/benchmark/jobfiles/jobfile_benchmark_speed_cpu.sh``
.. _jobfile_speed_cpu_sh: https://github.com/ameli/imate/blob/main/benchmark/jobfiles/jobfile_benchmark_speed_cpu.sh

.. |jobfile_openblas_sh| replace:: ``/imate/benchmark/jobfiles/jobfile_benchmark_openblas_dense.sh``
.. _jobfile_openblas_sh: https://github.com/ameli/imate/blob/main/benchmark/jobfiles/jobfile_benchmark_openblas_dense.sh

.. |notebook_openblas_dense_ipynb| replace:: ``/imate/benchmark/notebooks/plot_benchmark_openblas_dense.ipynb``
.. _notebook_openblas_dense_ipynb: https://github.com/ameli/imate/blob/main/benchmark/notebooks/plot_benchmark_openblas_dense.ipynb

.. |notebook_openblas_sparse_ipynb| replace:: ``/imate/benchmark/notebooks/plot_benchmark_openblas_sparse.ipynb``
.. _notebook_openblas_sparse_ipynb: https://github.com/ameli/imate/blob/main/benchmark/notebooks/plot_benchmark_openblas_sparse.ipynb

.. |svg_plots| replace:: ``/imate/benchmark/svg_plots/``
.. _svg_plots: https://github.com/ameli/imate/blob/main/benchmark/svg_plots
