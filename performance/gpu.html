


<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Performance on GPU Farm &#8212; imate Manual</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "auto";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom-pydata.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/toggleprompt.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom-pydata.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/logo-imate.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <script defer data-domain="docs.scipy.org" src="https://views.scientific-python.org/js/script.js"></script>

    <!-- Adobe Embed API -->
    <script src="https://documentcloud.adobe.com/view-sdk/viewer.js"></script>

    <!-- My custom JS -->
    <script type="text/javascript" src="../_static/js/custom-pydata.js"></script>

    <!-- Syntax highlighting for BibTex code blocks -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-solarizedlight.min.css"/>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js"></script>

    
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">

  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="auto">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../contents.html">
  
  
  
  
    <img src="../_static/images/icons/logo-imate-light.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/images/icons/logo-imate-dark.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/install.html">
  1. Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/docker.html">
  2. Docker
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials/gpu.html">
  3. GPU
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ameli/imate" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://pypi.org/project/imate/" rel="noopener" target="_blank" title="PyPI"><span><i class="fab fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://anaconda.org/s-ameli/imate" rel="noopener" target="_blank" title="Anaconda Cloud"><span><i class="fa fa-circle-notch"></i></span>
            <label class="sr-only">Anaconda Cloud</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://hub.docker.com/r/sameli/imate" rel="noopener" target="_blank" title="Docker Hub"><span><i class="fab fa-docker"></i></span>
            <label class="sr-only">Docker Hub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://mybinder.org/v2/gh/ameli/imate/HEAD?filepath=notebooks%2FInterpolateTraceOfInverse.ipynb" rel="noopener" target="_blank" title="Lanuch Jupyter on Binder"><span><i class="fa fa-chart-line"></i></span>
            <label class="sr-only">Lanuch Jupyter on Binder</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
    
    
  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#test-description">
   Test Description
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     Algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hardware">
     Hardware
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#benchmark-matrices">
   Benchmark Matrices
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arithmetic-types">
     Arithmetic Types
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scalability-with-data-size">
     Scalability with Data Size
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#extreme-array-sizes">
       Extreme Array Sizes
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#beyond-extreme-array-sizes">
       Beyond Extreme Array Sizes
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#floating-point-arithmetic-accuracy">
     Floating Point Arithmetic Accuracy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scalability-with-increase-of-gpu-devices">
     Scalability with Increase of GPU Devices
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-reproduce-results">
   How to Reproduce Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-locally">
     Run Locally
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#submit-job-to-cluster-with-slurm">
     Submit Job to Cluster with SLURM
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      

<div class="tocsection editthispage">
    <a href="https://github.com/https://github.com/ameli/imate/edit/main/docs/source/performance/gpu.rst">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="performance-on-gpu-farm">
<span id="perf-gpu"></span><h1>Performance on GPU Farm<a class="headerlink" href="#performance-on-gpu-farm" title="Permalink to this heading">#</a></h1>
<p>The performance of <span class="synco">imate</span> is tested on multi-GPU devices and the results are compared with the performance on a CPU cluster.</p>
<section id="test-description">
<h2>Test Description<a class="headerlink" href="#test-description" title="Permalink to this heading">#</a></h2>
<p>The performance test computes the quantity</p>
<div class="math notranslate nohighlight" id="equation-traceinv">
<span class="eqno">(1)<a class="headerlink" href="#equation-traceinv" title="Permalink to this equation">#</a></span>\[\mathrm{trace}(\mathbf{A}^{-1}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is symmetric and positive-definite. The above quantity is a computationally expensive expression that frequently appears in the Jacobian and Hessian of likelihood functions in machine learning.</p>
<section id="algorithm">
<h3>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this heading">#</a></h3>
<p>To compute <a class="reference internal" href="#equation-traceinv">(1)</a>, the stochastic Lanczos quadrature (SLQ) algorithm is employed. The complexity of this algorithm is</p>
<div class="math notranslate nohighlight" id="equation-complexity1">
<span class="eqno">(2)<a class="headerlink" href="#equation-complexity1" title="Permalink to this equation">#</a></span>\[ \mathcal{O} \left( (\mathrm{nnz}(\mathbf{A}) l + n l^2) s \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the matrix size, <span class="math notranslate nohighlight">\(\mathrm{nnz}(\mathbf{A})\)</span> is the number of nonzero elements of the sparse matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, <span class="math notranslate nohighlight">\(l\)</span> is the number of Lanczos iterations, and <span class="math notranslate nohighlight">\(s\)</span> is the number of Monte-Carlo iterations (see details in <a class="reference internal" href="../api/imate.traceinv.slq.html#imate-traceinv-slq"><span class="std std-ref">imate.traceinv(method=’slq’)</span></a>).  The numerical experiment is performed with <span class="math notranslate nohighlight">\(l=80\)</span> and <span class="math notranslate nohighlight">\(s=200\)</span>.</p>
</section>
<section id="hardware">
<h3>Hardware<a class="headerlink" href="#hardware" title="Permalink to this heading">#</a></h3>
<p>The computations were carried out on the following hardware:</p>
<ul class="simple">
<li><p>For <strong>CPU</strong> test: Intel(R) Xeon(R) CPU E5-2670 v3  with 24 threads.</p></li>
<li><p>For <strong>GPU</strong> test: a cluster of eight <a class="reference external" href="https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090-3090ti/">NVIDIA® GeForce RTX 3090</a> GPUs and Intel Xeon Processor (Skylake, IBRS) with 32 threads.</p></li>
</ul>
</section>
</section>
<section id="benchmark-matrices">
<h2>Benchmark Matrices<a class="headerlink" href="#benchmark-matrices" title="Permalink to this heading">#</a></h2>
<p>The table below shows the matrices used in the test, which are chosen from <a class="reference external" href="https://sparse.tamu.edu">SuiteSparse Matrix Collection</a> that are generated for real applications. The matrices in the table below are all symmetric positive-definite and the number of nonzero elements (nnz) of these matrices increase approximately by the factor of 5 on average.</p>
<table class="right2 right3 table">
<thead>
<tr class="row-odd"><th class="head"><p>Matrix Name</p></th>
<th class="head"><p>Size</p></th>
<th class="head"><p>nnz</p></th>
<th class="head"><p>Application</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://sparse.tamu.edu/HB/nos5"><code class="docutils literal notranslate"><span class="pre">nos5</span></code></a></p></td>
<td><p>468</p></td>
<td><p>5,172</p></td>
<td><p>Structural Problem</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sparse.tamu.edu/Bai/mhd4800b"><code class="docutils literal notranslate"><span class="pre">mhd4800b</span></code></a></p></td>
<td><p>4,800</p></td>
<td><p>27,520</p></td>
<td><p>Electromagnetics</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://sparse.tamu.edu/Pothen/bodyy6"><code class="docutils literal notranslate"><span class="pre">bodyy6</span></code></a></p></td>
<td><p>19,366</p></td>
<td><p>134,208</p></td>
<td><p>Structural Problem</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sparse.tamu.edu/AMD/G2_circuit"><code class="docutils literal notranslate"><span class="pre">G2_circuit</span></code></a></p></td>
<td><p>150,102</p></td>
<td><p>726,674</p></td>
<td><p>Circuit Simulation</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://sparse.tamu.edu/Wissgott/parabolic_fem"><code class="docutils literal notranslate"><span class="pre">parabolic_fem</span></code></a></p></td>
<td><p>525,825</p></td>
<td><p>3,674,625</p></td>
<td><p>Computational Fluid Dynamics</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sparse.tamu.edu/Janna/StocF-1465"><code class="docutils literal notranslate"><span class="pre">StocF-1465</span></code></a></p></td>
<td><p>1,465,137</p></td>
<td><p>21,005,389</p></td>
<td><p>Computational Fluid Dynamics</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://sparse.tamu.edu/Janna/Bump_2911"><code class="docutils literal notranslate"><span class="pre">Bump_2911</span></code></a></p></td>
<td><p>2,911,419</p></td>
<td><p>127,729,899</p></td>
<td><p>Structural Problem</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://sparse.tamu.edu/Janna/Queen_4147"><code class="docutils literal notranslate"><span class="pre">Queen_4147</span></code></a></p></td>
<td><p>4,147,110</p></td>
<td><p>329,499,284</p></td>
<td><p>Structural Problem</p></td>
</tr>
</tbody>
</table>
<section id="arithmetic-types">
<h3>Arithmetic Types<a class="headerlink" href="#arithmetic-types" title="Permalink to this heading">#</a></h3>
<p>The benchmark test also examines the performance and accuracy of <span class="synco">imate</span> on various arithmetic types of the matrix data. To this end, each of the above matrices were re-cast into 32-bit, 64-bit, and 128-bit floating point arithmetics. Depending on the hardware, the followings data types were tested:</p>
<ul class="simple">
<li><p>For <strong>CPU</strong> test: 32-bit, 64-bit and 128-bit floating point data.</p></li>
<li><p>For <strong>GPU</strong> test: 32-bit, 64-bit floating point data.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Supporting 128-bit data types is one of the features if <span class="synco">imate</span>, which is often not available in numerical libraries.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>NVIDIA CUDA libraries do not support 128-data types.</p>
</div>
</section>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this heading">#</a></h2>
<section id="scalability-with-data-size">
<h3>Scalability with Data Size<a class="headerlink" href="#scalability-with-data-size" title="Permalink to this heading">#</a></h3>
<p>The figure below shows the scalability by the relation between the elapsed (wall) time versus the data size.</p>
<p>The data size is indicated by the matrix nnz (rather than the matrix size). However, the matrix size can be found by the hollow circle marks in the figure.</p>
<ul class="simple">
<li><p><strong>GPU</strong> test: 8 GPU devices were used.</p></li>
<li><p><strong>CPU</strong> test: 16 CPU cores were used.</p></li>
</ul>
<figure class="align-center">
<a class="custom-dark reference internal image-reference" href="../_images/benchmark_speed_time.png"><img alt="../_images/benchmark_speed_time.png" class="custom-dark" src="../_images/benchmark_speed_time.png" style="height: 375px;" /></a>
</figure>
<aside class="custom-sidebar sidebar">
<p class="sidebar-title">Scalability Exponent</p>
<blockquote>
<div><table class="custom-table table">
<thead>
<tr class="row-odd"><th class="head"><p>Device</p></th>
<th class="head"><p>Data</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\alpha\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="3"><p>CPU</p></td>
<td><p>32-bit</p></td>
<td><p>1.08</p></td>
</tr>
<tr class="row-odd"><td><p>64-bit</p></td>
<td><p>0.89</p></td>
</tr>
<tr class="row-even"><td><p>128-bit</p></td>
<td><p>0.93</p></td>
</tr>
<tr class="row-odd"><td rowspan="2"><p>GPU</p></td>
<td><p>32-bit</p></td>
<td><p>0.86</p></td>
</tr>
<tr class="row-even"><td><p>64-bit</p></td>
<td><p>0.92</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
</aside>
<p>The computation on GPU is advantageous over CPU at nnz larger than roughly <span class="math notranslate nohighlight">\(10^{5}\)</span>. The elapsed time <span class="math notranslate nohighlight">\(t\)</span> is related to the number of nonzero elements <span class="math notranslate nohighlight">\(\mathrm{nnz}\)</span> by</p>
<div class="math notranslate nohighlight">
\[t \propto \mathcal{O}((\mathrm{nnz}(\mathbf{A}))^{\alpha}),\]</div>
<p>where the exponent <span class="math notranslate nohighlight">\(\alpha\)</span> for each experiment asymptotically approaches to the values shown in the table below. It can be seen that the performance is close to the theoretical complexity <a class="reference internal" href="#equation-complexity1">(2)</a>.</p>
<p>Also, the figure shows that processing 32-bit data is at most twice faster than 64-bit data on both CPU and GPU, and 64-bit data is at least twice faster than 128-bit on CPU.</p>
<section id="extreme-array-sizes">
<h4>Extreme Array Sizes<a class="headerlink" href="#extreme-array-sizes" title="Permalink to this heading">#</a></h4>
<p>There above results indicate <span class="synco">imate</span> is highly scalable on both CPU and GPU on massive data. However, there are a number of factors that can limit the data size. For instance, hardware memory limit is one such factor. Another limiting factor is the maximum array length in bits to store the content of a sparse matrix. Interestingly, this factor is not a hardware limitation, rather, is related to the maximum integer (often 32-bit <code class="docutils literal notranslate"><span class="pre">int</span></code> type) to index the array (in bits) on the memory. The 128-bit format of <a class="reference external" href="https://sparse.tamu.edu/Janna/Queen_4147"><code class="docutils literal notranslate"><span class="pre">Queen_4147</span></code></a> matrix is indeed close to such limit. The above results show that <span class="synco">imate</span> is scalable to large scales before reaching such an array size limit.</p>
</section>
<section id="beyond-extreme-array-sizes">
<h4>Beyond Extreme Array Sizes<a class="headerlink" href="#beyond-extreme-array-sizes" title="Permalink to this heading">#</a></h4>
<p><span class="synco">imate</span> can be configured to handle even larger data (if one can indeed store such array of data). To do so, increase the integer space for matrix indices by changing <code class="docutils literal notranslate"><span class="pre">UNSIGNED_LONG_INT=1</span></code> in <a class="reference external" href="https://github.com/ameli/imate/blob/main/imate/_definitions/definitions.h#L57"><code class="docutils literal notranslate"><span class="pre">/imate/imate/_definitions/definition.h</span></code></a> file, or in terminal set</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" data-sync-id="unix" for="sd-tab-item-0">
UNIX</label><div class="sd-tab-content docutils">
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt1:before {
  content: "$ ";
}
</style><span class="prompt1"><span class="nb">export</span> <span class="nv">UNSIGNED_LONG_INT</span><span class="o">=</span><span class="m">1</span></span>
</pre></div></div></div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" data-sync-id="win" for="sd-tab-item-1">
Windows (Powershell)</label><div class="sd-tab-content docutils">
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt2:before {
  content: "PS C:\\> ";
}
</style><span class="prompt2"><span class="nv">$env:export</span> <span class="n">UNSIGNED_LONG_INT</span> <span class="p">=</span> <span class="s2">&quot;1&quot;</span></span>
</pre></div></div></div>
</div>
<p>Then, recompile <span class="synco">imate</span>. See <a class="reference internal" href="../tutorials/install.html#compile-source"><span class="std std-ref">Compile from Source</span></a>.</p>
</section>
</section>
<section id="floating-point-arithmetic-accuracy">
<h3>Floating Point Arithmetic Accuracy<a class="headerlink" href="#floating-point-arithmetic-accuracy" title="Permalink to this heading">#</a></h3>
<p>The error of floating point arithmetic of iterative algorithms is sensible on large data. In this test, the result of 32-bit and 64-bit data are compared with the result of 128-bit as a benchmark and shown in the figure below. The results show that both 32-bit and 64-bit data have less than <span class="math notranslate nohighlight">\(0.1 \%\)</span> error relative to 128-bit data. However, for data larger than <span class="math notranslate nohighlight">\(10^{7}\)</span>, the error of 32-bit data is <span class="math notranslate nohighlight">\(30 \%\)</span> relative to 128-bit data whereas 64-bit data maintain <span class="math notranslate nohighlight">\(0.1 \sim 1 \%\)</span> error. Because of this, 64-bit data is often a good balance between accuracy and speed.</p>
<a class="custom-dark reference internal image-reference" href="../_images/benchmark_speed_accuracy.png"><img alt="../_images/benchmark_speed_accuracy.png" class="custom-dark align-center" src="../_images/benchmark_speed_accuracy.png" style="height: 375px;" /></a>
</section>
<section id="scalability-with-increase-of-gpu-devices">
<h3>Scalability with Increase of GPU Devices<a class="headerlink" href="#scalability-with-increase-of-gpu-devices" title="Permalink to this heading">#</a></h3>
<p>The scalability of <span class="synco">imate</span> is examined by the increase of the number of CPU threads or GPU devices as shown in the figure below.</p>
<a class="custom-dark reference internal image-reference" href="../_images/benchmark_speed_cores.png"><img alt="../_images/benchmark_speed_cores.png" class="custom-dark align-center" src="../_images/benchmark_speed_cores.png" style="height: 375px;" /></a>
<br/><aside class="custom-sidebar sidebar">
<p class="sidebar-title">Scalability Exponent</p>
<blockquote>
<div><table class="custom-table table">
<thead>
<tr class="row-odd"><th class="head"><p>Device</p></th>
<th class="head"><p>Data</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\beta\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="3"><p>CPU</p></td>
<td><p>32-bit</p></td>
<td><p>0.83</p></td>
</tr>
<tr class="row-odd"><td><p>64-bit</p></td>
<td><p>0.80</p></td>
</tr>
<tr class="row-even"><td><p>128-bit</p></td>
<td><p>0.76</p></td>
</tr>
<tr class="row-odd"><td rowspan="2"><p>GPU</p></td>
<td><p>32-bit</p></td>
<td><p>0.98</p></td>
</tr>
<tr class="row-even"><td><p>64-bit</p></td>
<td><p>0.96</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
</aside>
<p>The above results correspond to only <a class="reference external" href="https://sparse.tamu.edu/Janna/Queen_4147"><code class="docutils literal notranslate"><span class="pre">Queen_4147</span></code></a>, which is the largest matrix on the list. The performance on GPUs are over thirty-fold faster than the CPU for the same number of threads and GPU devices, although, this may not be a fair comparison. However, the performance of one GPU device is yet five times faster than 8 CPU threads.</p>
<p>The elapsed (wall) time, <span class="math notranslate nohighlight">\(t\)</span>, can be related to the number of CPU threads or GPU devices, <span class="math notranslate nohighlight">\(m\)</span>, as</p>
<div class="math notranslate nohighlight">
\[t \propto \mathcal{O}(m^{-\beta}).\]</div>
<p>The estimated values of <span class="math notranslate nohighlight">\(\beta\)</span> from the curves on the figure are shown in the table below. The speed (inverse of elapsed time) per CPU thread tend to saturate by the increase off the number of CPU threads. In contrast, the GPU results show better scalability as it maintains the linear behaviour by the increase of the number of GPU devices.</p>
</section>
</section>
<section id="how-to-reproduce-results">
<h2>How to Reproduce Results<a class="headerlink" href="#how-to-reproduce-results" title="Permalink to this heading">#</a></h2>
<p>Scripts to reproduce the above results is available</p>
<section id="run-locally">
<h3>Run Locally<a class="headerlink" href="#run-locally" title="Permalink to this heading">#</a></h3>
<p>Run the script <a class="reference external" href="https://github.com/ameli/imate/blob/main/benchmark/scripts/benchmark_speed.py"><code class="docutils literal notranslate"><span class="pre">/imate/benchmark/scripts/benchmark_speed.py</span></code></a> as follows.</p>
<ul>
<li><p>To test CPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">cd</span> /imate/benchmark/scripts</span>
<span class="prompt1">python ./benchmark_speed.py -c</span>
</pre></div></div></li>
<li><p>To test GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">cd</span> /imate/benchmark/scripts</span>
<span class="prompt1">python ./benchmark_speed.py -g</span>
</pre></div></div></li>
</ul>
</section>
<section id="submit-job-to-cluster-with-slurm">
<h3>Submit Job to Cluster with SLURM<a class="headerlink" href="#submit-job-to-cluster-with-slurm" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>The SLURM job file to submit the CPU test is available at <a class="reference external" href="https://github.com/ameli/imate/blob/main/benchmark/jobfiles/jobfile_benchmark_speed_cpu.sh"><code class="docutils literal notranslate"><span class="pre">/imate/benchmark/jobfiles/jobfile_benchmark_speed_cpu.sh</span></code></a>. Submit the job by</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">cd</span> /imate/benchmark/jobfiles</span>
<span class="prompt1">sbatch jobfile_benchmark_speed_cpu.sh</span>
</pre></div></div></li>
<li><p>The SLURM job file to submit the GPU test is available at <a class="reference external" href="https://github.com/ameli/imate/blob/main/benchmark/jobfiles/jobfile_benchmark_speed_gpu.sh"><code class="docutils literal notranslate"><span class="pre">/imate/benchmark/jobfiles/jobfile_benchmark_speed_gpu.sh</span></code></a>. Submit the job by</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1"><span class="nb">cd</span> /imate/benchmark/jobfiles</span>
<span class="prompt1">sbatch jobfile_benchmark_speed_gpu.sh</span>
</pre></div></div></li>
</ul>
</section>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, Siavash Ameli.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.1.1.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>